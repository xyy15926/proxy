#	Least Angle Regression

-	线性回归即找的一组系数能够用自变量的线性组合表示
	因变量
##	Forward Selection/Forward Stepwise Regression

Wesiberg[(1980), Section 8.5]

-	从所有给定predictors中选择和y相关系数绝对值最大的变量
	$x_{j1J$，做线性回归

	-	对于标准化后的变量，相关系数即为变量之间的内积
	-	变量之间相关性越大，变量的之间的夹角越小，单个变量
		能解释得效果越好
	-	此时残差同解释变量正交

-	将上一步剩余的残差作为reponse，将剩余变量投影到残差上
	重复选择步骤

	-	k步之后即可选出一组变量，然后用于建立普通线性模型

-	前向选择算法非常贪心，可能会漏掉一些有效的解释变量，只是
	因为同之前选出向量相关

##	Forward Stagewise

前向选择的catious版本

-	和前向选择一样选择和y夹角最小的变量，但是每次只更新较小
	步长，每次更新完确认和y夹角最小的变量，使用新变量进行
	更新

	-	同一个变量可能会被多次更新，即系数会逐渐增加
	-	每次更新一小步，避免了前向选择的可能会忽略关键变量


