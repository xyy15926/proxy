#	通用技术

##	抽样

###	抽样技术

####	*Hold Out*

旁置法：将样本集随机划分为训练集、测试集

-	适合样本量较大的场合

####	*N-fold Cross Validation*

N折交叉验证：旁置法的扩展，将数据分成N份，每次将其中一份作为
测试样本集，其余N-1份作为训练样本集

-	解决了留一法计算成本高的问题：重复次数少
-	克服了旁置法中测试样本选取随机性的问题：每个样本都能作为
	测试样本
-	典型的“袋外验证”：袋内数据（训练样本）、袋外数据（测试
	样本）分开

####	*Leave-One-Out Cross Validation*

留一法：对n个观测的样本集，每次选择一个观测作为测试样本集，
剩余n-1个观测值作为训练样本集，重复n次计算模型误差

-	可以看作是N折交叉验证的特例

####	Bootstrap

重抽样自举：对样本量为n的样本集S，做k次有放回的重复抽样，
得到k个样本容量仍然未n的随机样本$S_i(i=1,2,...,k)$，称为自举
样本（模拟多组独立样本）

###	样本评价

抽样样本与整体的相似性

$$\begin{align*}
J(S, D) & = \frac {1} {D} \sum_{k=1}^{r} J_{k}(S, D) \\
J_{k}(S, D) & = \sum_{j=1}^{N_k}(P_{Sj} - P_{Dj})
	log \frac {P_{Sj}} {P_{Dj}} \\
Q(s) & = exp(-J)
\end{align*}$$

> - $D$：数据集，包含$r$个属性
> - $S$：抽样样本集
> - $J_k=J(S, D)$：*Kullblack-Laible*信息量，数据集$S$、$D$
	在属性$k$上偏差程度，越小偏差越小
> - $Q(S) \in [0, 1]$：抽样集$S$在数据集$D$中的质量，越大
	样本集质量越高

####	说明

-	若整体$D$分布稀疏，容易得到$S$在某些数据点观测值数为0，
	得到$I(S, D) \rightarrow infty$

	-	可以把该点和附近的点频率进行合并，同时调整总体频率
		分布
	-	过度合并会导致无法有效衡量数据集局部差异性

-	对于连续型变量

	-	可以把变量进行适当分组：粗糙，不利于刻画数据集直接的
		局部差异
	-	计算数据集各个取值点的非参估计，如核估计、最近邻估计
		等，再在公式中用各自的非参估计代替相应频率，计算样本
		质量

-	数据包含多个指标时
	-	可以用多个指标的平均样本质量衡量整体样本质量
	-	也可以根据指标重要程度，设置不同的权重

