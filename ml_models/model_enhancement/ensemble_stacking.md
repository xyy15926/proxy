#	Stacked Generalization

##	Stacked Generalization

堆栈泛化：使用**多种模型**分别训练训练，将其结果叠加作为下层
模型的输入，最终得到预测输出

![stacking](imgs/stacking.png)

-	属于异源集成模型，可以视为

	-	复合函数

		![stacing_workflow_2](imgs/stacking_workflow_2.png)

	-	短路网络

		![stacing_workflow_1](imgs/stacking_workflow_1.png)

> - 从某种意义上，复杂模型都是stacking

###	思想

-	不同模型侧重于获取数据不同方面的特征
	-	使用基学习器抽取数据特征进行表示学习，提取不同角度的
		数据高维特征
	-	考虑到使用全量训练数据训练、预测作为下层模型输入会
		导致过拟合，可使用K折交叉验证避免过拟合
	-	有些基学习器只使用适合其部分特征训练
		-	GBDT、DNN适合低维稠密特征

-	元学习器组合多个基学习器的输出
	-	从数据高维特征学习数据模式，具有更好的泛化能力，避免
		过拟合

###	算法

> - 输入：模型$M_1, M_2, \cdots, M_d$、训练特征：$X_{n*m}$、
	训练标签$Y_{n}$、测试特征$X^{'}$
> - 输出：stacking模型、预测标签

-	将训练数据K折划分，对第$i$轮划分

	-	使用模型$M_1, M_2, \cdots, M_d$分别在相应训练集
		$[X[:n_i,:], X[n_{i+1}:,:]]$、
		$[Y[:n_i], Y[n_{i+1}:]]$上训练
	-	在相应验证集$X[n_i:n_{i+1}, :]$上验证、并记录验证
		结果
	-	将验证集验证结果叠加得到部分样本新特征
		$N[n_i: n_{i+1}, d]$

-	将K轮划分得到的部分新特征拼接得到训练集的完整新特征
	$N_{n * d}$，将新特征作为输入，训练下层模型，得到最终
	stacking模型

-	将测试特征如上作为输入经过两层模型预测，得到最终预测结果

> - 以上以2层stacking为例，有深层stacking




