#	随机算法

##	Simulated Annealing Algorithm

模拟退火算法

-	来源于固体退火原理
	-	将固体加热至充分高，固体内部粒子随之变为无序状，内能
		增加
	-	再让固体徐徐冷却，内部例子随之有序
	-	到达常温状态时，内能减为最小

-	用固体退火模拟**组合**优化问题
	-	目标函数值`f`视为内能`E`，控制参数`t`视为温度`T`
	-	由初始解`i`、控制参数初值`t`开始，对当前解重复
		*产生新解->计算目标函数增量->接受或舍弃*的迭代，并
		逐步衰减t值
	-	算法终止时，当前解即为所得近似最优解

-	退火过程由Cooling Schedule控制，包括控制参数初值t、衰减
	因子$\Delta t$、迭代次数L、停止条件S

###	算法

-	初始化：初始温度$t_0$（充分大）、初始解$i_0$、迭代次数L
-	产生新解$i_1$，计算目标函数增量$\Delta f=f(i_1)-f(i)$
-	若$\Delta f<0$则接受$i_1$作为新解，否则以概率
	$\exp^{\Delta f/f(i_0)}$接受$i_1$作为新解
-	若满足终止条件则算法结束
	-	若干次新解都不被接受：当前解“能量”低
	-	迭代次数达到上限
-	否则减小温度为$t_1$继续迭代

说明

-	解生成器：应该可以通过简单变换即可产生新解，便于减少每次
	迭代计算新解耗时
	-	比如对新解全部、部分元素进行置换、互换等
	-	需要注意的是，这决定了新解的领域结构，对冷却的进度表
		选取有影响

-	新解是否被接受采用的是Metropolis准则

###	模拟退火算法性质

-	与初值无关
-	具有渐进收敛性
-	具有并行性
-	在理论上被证明是以概率1收敛于全局最优解的算法
-	能够跳出局部最优解

###	应用

-	VLSI：目前退火模拟算法的应用实例，几乎可以完成所有VLSI
	设计工作
-	神经网络：模拟退火算法能够跳出局部最优解
-	图像处理：用于进行图像恢复工作
-	其他问题：还可以用于其他各种组合优化问题

##	*Genetic Algorithm*

遗传算法：模拟自然界生物进化过程，采用人工进化的方式对目标
空间进行搜索

-	本质是高效、并行、全局搜索方法
-	能在搜索过程中自动获取、积累有关搜索空间的知识，并自适应
	的控制搜索过程以求的最佳解

###	思想

-	将问题域中可能解看作是染色体，将其编码为符号串的形式
-	对染色体群体反复进行基于遗传学的操作：选择、交叉、变异
-	根据预定目标适应度函数对每个个体进行评价，不断得到更优
	群体，从中全局并行搜索得到优化群体中最优个体

####	实体

-	*population*：群体，GA的遗传搜索空间
-	*individual*：个体，搜索空间中可能解
-	*chromosome*：染色体，个体特征代表
	-	由若干段基因组成
	-	GA中基本操作对象
-	*gene*：基因
	-	染色体片段
-	*fitness*：适应度，个体对环境的适应程度

####	基本操作

-	*selection*：选择，根据个体适应度在群体中按照一定概率
	选择个体作为父本
	-	适应度大个体被选择概率高
	-	体现了适者生存、优胜劣汰的进化规则

-	*crossover*：交叉，将父本个体按照一定概率随机交换基因
	形成新个体

-	*mutate*：变异，按照一定概率随机改变某个体基因值

###	串编码方式

-	把问题的各种参数用二进串进行编码构成子串
-	把子串拼接成染色体
> - 串长度、编码方式对算法收敛影响极大

####	二进制编码方式

二进制法：使用二进制染色体表示所有特征

-	优点
	-	编码、解码操作简单
	-	交叉、变异等遗传操作便于实现
	-	符合最小字符集编码原则
	-	利于模式定理对算法理论分析

-	缺点
	-	连续函数离散化存在误差，染色体长度短时达不到精度
		要求，较长时解码难度大、搜索空间增大
	-	对连续函数优化问题，随机性使得其局部搜索能力较差，
		接近最优值时不稳定

####	浮点编码

浮点法：个体的每个基因值用某一范围内的一个浮点数表示

-	必须保证基因之在给定区间限制范围内
	-	交叉、变异等遗传算子结果也必须在限制范围内

-	优点
	-	适用于在遗传算法中表示范围较大的数
	-	精度较高
	-	便于较大空间的遗传搜索
	-	改善了遗传算法的计算复杂性，提高了运算效率
	-	便于遗传算法与经典优化方法的混合使用
	-	便于设计针对问题的专门知识的知识型遗传算子
	-	便于处理复杂的决策变量约束条件

####	符号编码法

符号法：个体染色体编码串基因值取自无意义字符集

-	优点
	-	符合有意义积木块编码原则
	-	方便利用所求解问题的专门知识
	-	访问GA和相关近似算法的混合使用

###	*Fitness Function*

适应度/对象函数

-	一般可以把问题模型函数作为对象函数

-	过程
	-	解码个体，得到个体表现型
	-	由个体表现型计算个体目标函数值
	-	根据最优化问题类型，由目标函数值按一定转换规则求出
		个体适应度

###	操作

####	选择函数

-	*Roulette Wheel Selection*：轮盘赌选择，个体进入下一代
	概率为其适应度与整个种群适应度之比
	-	放回式随机抽样
	-	选择误差较大

-	*Stochastic Tournament*：随机竞争选择，每次按轮盘赌选择
	一对个体，选择适应度较高者，重复直到选满

-	最佳保留选择：按轮盘赌选择方法执行遗传算法选择操作，然后
	将当前群体中适应度最高的个体结构完整地复制到下一代群体中

-	*Excepted Value Selection*：无回放随机选择，根据每个个体
	在下一代群体中的生存期望来进行随机选择运算

	-	计算群体中每个个体在下一代群体中的生存期望数目N
	-	若体被选中参与交叉运算，则它在下一代中的生存期望数目
		减去0.5，否则在下一代中的生存期望数目减去1.0
	-	随着选择过程的进行，当个体的生存期望数目小于0时，则
		该个体就不再有机会被选中。

-	确定式选择：按照一种确定的方式来进行选择操作

	-	计算群体中各个体在下一代群体中的期望生存数目N
	-	用N的整数部分确定个体在下一代群体中的生存数目
	-	用N的小数部分对个体进行降序排列，顺序取前M个个体加入
		到下一代群体
	-	完全确定出下一代群体中Ｍ个个体

-	无回放余数随机选择
	-	可确保适应度比平均适应度大的一些个体能够被遗传到
		下一代群体中
	-	选择误差比较小

-	均匀排序：对群体中的所有个体按期适应度大小进行排序，基于
	这个排序来分配各个个体被选中的概率

-	最佳保存策略：当前群体中适应度最高的个体不参与交叉运算
	和变异运算，而是用它来代替掉本代群体中经过交叉、变异等
	操作后所产生的适应度最低的个体

-	随机联赛选择：每次选取几个个体中适应度最高个体遗传到
	下一代群体中。

-	排挤选择：新生成的子代将代替或排挤相似的旧父代个体，提高
	群体的多样性

####	*Cross Over*

-	*One-point Crossover*：单点交叉，在个体编码串中只随机
	设置一个交叉点，然后再该点相互交换两个配对个体的部分
	染色体

-	*Two-point Crossover*：两点交叉，在个体编码串中随机设置
	两个交叉点，然后再进行部分基因交换

-	*Multi-point Crossover*：多点交叉

-	*Uniform Crossover*：均匀交叉/一致交叉，两个配对个体的
	每个基因座上的基因都以相同的交叉概率进行交换，从而形成
	两个新个体

-	*Arithmetic Crossover*：算术交叉，由两个个体的线性组合
	而产生出两个新的个体
	-	操作对象一般是由浮点数编码表示的个体

####	*Mutation*

-	*Simple Mutation*：基本位变异，对个体编码串中以变异概率
	、随机指定的某一位或某几位仅因座上的值做变异运算


-	*Uniform Mutation*：均匀变异，用符合某一范围内均匀分布
	的随机数，以较小的概率来替换个体编码串中各个基因座上原有
	基因值
	
	-	适用于在算法的初级运行阶段

-	*Boundary Mutation*：边界变异，随机的取基因座上的两个
	对应边界基因值之一去替代原有基因值
	
	-	适用于最优点位于或接近于可行解的边界时的一类问题

-	*非均匀变异*：对原有的基因值做一随机扰动，以扰动后的结果
	作为变异后的新基因值
	
	-	对每个基因值都以相同的概率进行变异运算之后，相当于
		整个解向量在解空间中作了一次轻微的变动

-	高斯近似变异：进行变异操作时用符号均值为P、方差$P^2$的
	正态分布的一个随机数来替换原有的基因值

###	GA超参设置

-	群体大小$n$：过小难以求出最优解，过大难收敛，一般取
	$n = 30 ~ 160$

-	交叉概率$P_c$：太小难以前向搜索，太大容易破坏高适应
	值结构，一般取$P_c = 0.25 ~ 0.75$

-	变异概率$P_m$：太小难以产生新结构，太大则变为单纯
	随机搜索，一般取$P_m = 0.01 ~ 0.2$

###	算法

1.	随机初始化种群
2.	估初始种群：为种群每个个体计算适应值、排序
3.	若没有达到预定演化数，则继续，否则结束算法
4.	选择父体
	-	杂交：得到新个体
	-	变异：对新个体变异
5.	计算新个体适应值，把适应值排名插入种群，淘汰最后个体
6.	重复3

##	数值随机化算法

数值化随机算法：常用于数值问题求解，往往得到的是近似解

-	近似解的精度随计算时间、采样数量增加不断提高
-	很多情况下计算问题的精确解不可能、无必要，数值化随机算法
	可以得到较好的解

###	随机投点法

随机投点法：在给定范围内生成均匀分布随机数模拟随机投点

-	计算$\pi$值：在正方形、内切圆中随机撒点，计算圆内、
	正方形内点数量之比

-	计算黎曼积分：在包括积分区域单位矩形内随机投点，计算
	积分区域、矩形区域点数量之比

###	平均值法

平均值法：结合随机数分布、目标问题构造统计量，估计目标问题

####	计算黎曼积分

-	假设独立同分布随机变量${\eta_i}$在$[a, b]$中服从分布
	$f(x)$、待积函数为$g(x)$

-	记$g^{*}(x) = \frac {g(x)} {f(x)}$，则有

	$$\begin{align*}
	E(g^{*}(\eta)) & = \int_a^b g^{*}f(x) dx \\
	& = \int_a^b g(x) dx = I
	\end{align*}$$

-	由强大数定理

	$$
	P_r(\lim_{x \rightarrow \infty} \frac 1 n \sum_{i=1}^n
		g^{*}(\eta_i) = I) = 1
	$$

	选择$\bar I = \frac 1 n \sum_{i=1}^n g^{*}(\eta_i)$，
	则$\bar I$依概率收敛为$I$

-	选择抽样方法简单的概率密度函数$f(x)$满足

	$$\left \{ \begin{array}{l}
	f(x) \neq 0, & g(x) \neq 0, a \leq x \leq b \\
	\int_a^b f(x) dx = 1
	\end{array} \right.$$

	可以取$f(x)$为均匀分布

	$$
	f(x) = \left \{ \begin{array}{l}
		\frac 1 {b-a}, & a \leq x \leq b \\
		0, & x < a, x > b
	\end{array} \right.
	$$

-	则积分

	$$
	I = \int_a^b g(x)dx = (b-a) \int_a^b g(x)
		\frac 1 {b-a}dx
	$$

	取均值

	$$
	\bar I = \frac {b-a} n \sum_{i=1}^n g(x_i)
	$$

	可作为求分I的近似值

###	解非线性方程组

$$\left \{ \begin{array}{l}
f_1(x) & = f_1(x_1, x_2, \cdots, x_n) & = 0 \\
f_2(x) & = f_2(x_1, x_2, \cdots, x_n) & = 0 \\
\vdots \\
f_n(x) & = f_n(x_1, x_2, \cdots, x_n) & = 0
\end{array} \right.$$

-	线性化方法、求函数极小值方法有时会遇到麻烦，甚至使方法
	失效而不能获得近似解
-	随机化方法相较而言要耗费较多时间，但设计简单、易于实现
-	对于精度要求较高的问题，随机化方法可以提供一个较好的初值

####	步骤

-	构造目标函数

	$$
	\Phi(x) = \sum f_i^2(x)
	$$

	则目标函数的极小值点即为所求非线性方程组的一组解

-	随机选择点$x_0$作为出发点，不断**随机生成搜索方向**，
	迭代为使得目标函数值下降的搜索点

	-	一般以目标函数变化幅度、迭代轮数作为终止条件
	-	搜索方向为随机生成，迭代步长比例每轮缩小指定幅度

> - 真正的**随机次梯度下降**

##	*Monte Carol Method*

蒙特卡洛算法：一定能给出问题解，但未必正确

-	要求在有限时间、采样内必须给出解，解未必正确
-	求得正确解的概率依赖于算法所用时间，算法所用时间越多，
	得到正确解概率越高
-	无法有效判断得到的解是否肯定正确

##	*Las Vegas Method*

拉斯维加斯算法：找到的解一定是正确解，但是可能找不到解

-	找到正确解的概率随着计算所用时间增加而提高
-	用同一拉斯维加斯算法反复对实例求解多次，可使得求解失效
	概率任意小

##	*Sherwood Method*

舍伍德算法：能求得问题的一个解，所求得得解总是正确的

-	确定性算法在最好情况、平均情况下计算复杂度有较大差别，
	在确定性算法中引入随机性将其改造成舍伍德算法，消除、减少
	问题的好坏实例间差别

-	精髓不是改进算法在最坏情形下的行为，而是设法消除最坏情形
	与特定问题实例的关联性

###	思想

-	问题输入规模为n时，算法A所需的平均时间为

	$$
	\bar t_A(n) = \sum_{x \in X_n} t_A(x) / |X_n|
	$$

	> - $X_n$：算法A输入规模为n的实例全体
	> - $t_A(x)$：输入实例为x时所需的计算时间

	显然存在$x \in X_n, t_A(x) >> \bar t_A(x)$

-	希望获得随机化算法B，使得对问题的输入规模为n的每个实例
	$x \in X_n$均有$t_B(x) = \bar t_A(x) + s(n)$

	-	对具体实例，存在$x \in X_n$，算法B需要时间超过
		$\bar t_A(x) + s(n)$，但这是由于算法所做的概率引起，
		与具体实例无关

	-	算法B关于规模为n的随机实例平均时间为

		$$\begin{align*}
		\bar t_B(n) & = \sum_{x \in X_n} t_B(x) / (X_n) \\
		& = \bar t_A(n) + s(n)
		\end{align*}$$K

		当$s(n)$与$\bar t_A(n)$相比可以忽略时，舍伍德算法
		可以获得较好平均性能

#todo

